### From what I gather, Dura Digital can be considered an AI technology consultancy company. Typically, who is the point of contact? And how does human behavior play into developing a solution?

> Kyle Myck: Our engagement model is to make sure the right people are in the right conversation. Often, it'll be Fernando, our CEO, or myself who will initiate conversations. Once we start working with them, our goal is to understand where we can help. Definitely, the human approach for us is really important. Even before AI took hold, we had our Human-Centered Design Studio, which is focused on establishing empathy with the users. We have a lot of processes in place to make sure humans are always front and center.

### Do you normally speak with somebody who's technical or non-technical when it comes to such a consultancy scheme?

> Kyle Myck: Both. It really depends on the client. We work with clients as large as Microsoft—so very large organizations. Of course, within those clients, there's technical folks, strategy people, business people; we work with all of them. Some of our smaller to medium-sized clients often don't have people who are very technical, so we do help fill that gap.

### When you're scoping a project for a new client, are cost and model performance the main factors? Or are there others?

> Kyle Myck: We've been quite intentional on being as technology agnostic as we can. We want to be able to meet clients where they're at. We don't want to have any sort of bias just because that's our experience. That general approach follows its way into AI as well. We try to be really thoughtful in not being too prescriptive, so we don't back an organization into a corner where they're tied to a model that makes it hard to switch.

### It's a very fast-moving scene. What would make you decide between different models or ecosystems?

> Kyle Myck: Some of the other factors are just fit. Large clients often work within an ecosystem already. We wouldn't recommend to Microsoft that they use Google Gemini. We try to tailor the way we approach the problem based on what the organization has access to. If we're starting more greenfield, part of it is just fit. Often we'll leverage Perplexity for search, or Gemini, or OpenAI’s mini models for performance. It's dependent on the use case.

### A lot of companies are rushing to adopt AI without putting the right guardrails in place. Are there risks if a company decides to do it independently just for speed to market?

> Kyle Myck: Yeah, I think there is significant risk. Just as frequently as we see announcements about new models, we see highlights of where there have been issues or AI used in nefarious ways. You have to take a lot of the learnings we've had of creating software over the last few decades and apply those the same way—securing APIs, being thoughtful about access—and not just get excited about the LLM solving something for you.

### How do you approach integrating AI into older legacy systems? Do you usually have to just rip it apart and build it fresh?

> Kyle Myck: It depends on the problem we're trying to solve. Often, even with some legacy applications, there's an API layer that's good enough to support most experiences. It's very infrequent that we have to tear things down all the way to the database level. But that data layer and integration layer are really important for supporting AI solutions.

### For rapid prototyping, do you normally opt for no-code solutions just to get a demo out quickly, or do you code it out?

> Kyle Myck: Our design team is really good at creating prototypes or high-fidelity mockups in Figma. Typically we have some sort of mockup before we start the software development side. We don't often go directly to no-code solutions because our design team is so efficient. However, for automation proof of concepts, we often use **n8n** just to see if the integration and tying agents together work well.

### Without giving away too much, what is a misconception about integrating AI into a company that you think is out there?

> Kyle Myck: I think approaching AI at the "right level" is something we try to do. There are three layers:
> 1. **The Productivity Layer:** Access to Gemini, Copilots, GPTs. Anyone can use these as a companion.
> 2. **The Engineering/Agent Layer:** Getting the most out of large LLMs using RAG pipelines, agentic approaches, or Model Context Protocol (MCP).
> 3. **The Foundation Layer:** Creating bespoke models or training models on something specific.
>
> A major misconception is that AI is the magic bullet. AI doesn't always solve the problem. Traditional automation is still sometimes much more efficient and predictable than AI. You have to determine if AI really helps the user experience or if it just makes it confusing.